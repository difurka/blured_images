{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Обучение модели\n",
        "\n",
        "Можно также запустить на [Colab](https://colab.research.google.com/drive/1rvnfzs4RFacs28ulCl63FRZu4nZzBsCn?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-AIkHcjMbL-C"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import zipfile\n",
        "from collections.abc import Callable\n",
        "from pathlib import Path, PosixPath\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models import Inception_V3_Weights\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3CK5c5Qa2bS",
        "outputId": "a00f66c1-93c3-4edd-c496-80e9e60796fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbalakinakate2022\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "bXwfoD20a61_",
        "outputId": "db4056ee-4dd7-49d2-d108-992829a77ca3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230323_041949-gofyodks</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/balakinakate2022/pipeline_competition/runs/gofyodks' target=\"_blank\">balmy-water-368</a></strong> to <a href='https://wandb.ai/balakinakate2022/pipeline_competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/balakinakate2022/pipeline_competition' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/balakinakate2022/pipeline_competition/runs/gofyodks' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition/runs/gofyodks</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact my-dataset:v0, 150.47MB. 1 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
            "Done. 0:0:0.3\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Load dataset from W&B.\"\"\"\n",
        "DIR = './data/'\n",
        "DIR_ZIP = './artifacts/my-dataset:v0/'\n",
        "\n",
        "run = wandb.init(project=\"pipeline_competition\")\n",
        "artifact = run.use_artifact('balakinakate2022/pipeline_competition/my-dataset:v0', type='dataset')\n",
        "artifact.download()\n",
        "\n",
        "with zipfile.ZipFile(DIR_ZIP+\"shift-cv-winter-2023.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3xqW7MalbeIW"
      },
      "outputs": [],
      "source": [
        "\"\"\"Create model.\"\"\"\n",
        "\n",
        "def get_model(): \n",
        "    model_inception_v3 = models.inception_v3(weights=Inception_V3_Weights.IMAGENET1K_V1)\n",
        "    model_inception_v3.aux_logits = False\n",
        "    # num_features - размерность вектора фич, поступающего на вход FC\n",
        "    num_features = 2048\n",
        "    # n_classes - количество классов, которые будет предсказывать наша модель\n",
        "    n_classes = 2\n",
        "    # Заменяем Fully-Connected слой на наш линейный классификатор\n",
        "    model_inception_v3.fc = nn.Linear(in_features=num_features, out_features=n_classes)\n",
        "    model_inception_v3.AuxLogits.fc = nn.Linear(768, 2)\n",
        "\n",
        "    return model_inception_v3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5uMkjUXbbsRu"
      },
      "outputs": [],
      "source": [
        "\"\"\"Prepare datasets.\"\"\"\n",
        "\n",
        "# режимы датасета \n",
        "DATA_MODES = ['train', 'val', 'test']\n",
        "# все изображения масштабируем к размеру 299*299 px\n",
        "RESCALE_SIZE = 299\n",
        "\n",
        "class CastomDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Датасет картинок, который паралельно подгружает их из папок\n",
        "    производит скалирование и превращение в торчевые тензоры\n",
        "    \"\"\"\n",
        "    def __init__(self, files: np.array,  mode: str, data_labels: pd.core.frame.DataFrame = None, \n",
        "                 transform: transforms.Compose=None):\n",
        "        \"\"\"\n",
        "        Конструктор датасета.\n",
        "\n",
        "        Args:\n",
        "            files (np.array): список путей до изображений\n",
        "            mode (str): тип датасета из ['train', 'val', 'test']\n",
        "            data_labels (pd.core.frame.DataFrame, optional): _description_. Defaults to None.\n",
        "            transform (transforms.Compose, optional): преобразования датасета\n",
        "\n",
        "        Raises:\n",
        "            NameError: возникает в случае неправильного типа датамета\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # список файлов для загрузки\n",
        "        self.files = sorted(files)\n",
        "        # режим работы\n",
        "        self.mode = mode\n",
        "        self.transform = transform\n",
        "        self.data_labels = data_labels\n",
        "\n",
        "        if self.mode not in DATA_MODES:\n",
        "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
        "            raise NameError\n",
        "        self.len_ = len(self.files)\n",
        "\n",
        "        # загружем метки файлов\n",
        "        if self.mode != 'test':\n",
        "            self.labels = torch.tensor([np.array(self.data_labels[self.data_labels.iloc[:, 0] == path.name].iloc[:,1])[0] \\\n",
        "                        for path in self.files],dtype=torch.long)  \n",
        "                        \n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Количество элементов в датасете.\n",
        "\n",
        "        Returns:\n",
        "            int: количество элементов \n",
        "        \"\"\"\n",
        "        return self.len_\n",
        "    \n",
        "    def load_sample(self, file: PosixPath) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Загружает изображение, находящееся по пути file.\n",
        "\n",
        "        Args:\n",
        "            file (PosixPath): путь до изображения\n",
        "\n",
        "        Returns:\n",
        "            Image.Image: изображение\n",
        "        \"\"\"\n",
        "        image = Image.open(file)\n",
        "        image.load()\n",
        "        return image\n",
        "\n",
        "    def __getitem__(self, index: int) -> Tuple[np.array, int]:\n",
        "        \"\"\"\n",
        "        Возвращает элемент датасета.\n",
        "\n",
        "        Args:\n",
        "            index (int): индекс элемента датасета\n",
        "\n",
        "        Returns:\n",
        "            Tuple[np.array, int]: изображение и размыто/неразмыто\n",
        "        \"\"\"\n",
        "        x = self.load_sample(self.files[index])\n",
        "        x = self._prepare_sample(x)\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "        if self.mode == 'test':\n",
        "            return x\n",
        "        else:\n",
        "            y = self.labels[index]\n",
        "            return x, y\n",
        "        \n",
        "    def _prepare_sample(self, image: Image.Image) -> np.array:\n",
        "        \"\"\"\n",
        "        Уменьшение размера изображения.\n",
        "\n",
        "        Args:\n",
        "            image (Image.Image): входящее изображение\n",
        "\n",
        "        Returns:\n",
        "            np.array: уменьшенное изображение\n",
        "        \"\"\"\n",
        "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
        "        return np.array(image)\n",
        "    \n",
        "\n",
        "def get_datasets() -> Tuple[CastomDataset, CastomDataset, CastomDataset]:\n",
        "    \"\"\"\n",
        "    Create datasets for train, validate, predict.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[CastomDataset, CastomDataset, CastomDataset]: train_dataset, val_dataset, test_dataset\n",
        "    \"\"\"\n",
        "    DIR = './data/'\n",
        "    TRAIN_DIR = Path(DIR + 'train/train')\n",
        "    TEST_DIR = Path(DIR + 'test/test')\n",
        "\n",
        "    # load_from_WB()\n",
        "\n",
        "    train_val_files = list(TRAIN_DIR.rglob('*.jpg'))\n",
        "    test_files = list(TEST_DIR.rglob('*.jpg'))\n",
        "\n",
        "    data_labels = pd.read_csv(DIR + 'train.csv')\n",
        "    data_labels[['blur']] = data_labels[['blur']].astype('long')\n",
        "\n",
        "    transform_train = transforms.Compose([\n",
        "                transforms.ToPILImage(),\n",
        "                transforms.RandomVerticalFlip(0.5),\n",
        "                transforms.RandomHorizontalFlip(0.5),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "    transform_test = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "    train_val_files = list(TRAIN_DIR.rglob('*.jpg'))\n",
        "    test_files = list(TEST_DIR.rglob('*.jpg'))\n",
        "\n",
        "    train_val_labels = [np.array(data_labels[data_labels.iloc[:, 0] == path.name].iloc[:,1])[0] for path in train_val_files]\n",
        "    train_files, val_files = train_test_split(train_val_files, test_size=0.25, stratify=train_val_labels)\n",
        "\n",
        "    train_dataset = CastomDataset(train_files, data_labels=data_labels, mode='train', transform=transform_train)\n",
        "    val_dataset = CastomDataset(val_files, data_labels=data_labels, mode='val', transform=transform_test)\n",
        "    test_dataset = CastomDataset(test_files, mode='test', transform=transform_test)\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XRwSAjtIbs0F"
      },
      "outputs": [],
      "source": [
        "\"\"\"Functions for training and validation.\"\"\"\n",
        "\n",
        "def seed_everything(seed: int):\n",
        "    \"\"\"\n",
        "    Make default settings for random values.\n",
        "\n",
        "    Args:\n",
        "        seed (int): seed for random\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import random\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True \n",
        "    # будет работать - если граф вычислений не будет меняться во время обучения\n",
        "    torch.backends.cudnn.benchmark = True  # оптимизации\n",
        "\n",
        "\n",
        "def model_learning(    \n",
        "    model: nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    criterion: Callable,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    device: Callable,\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Make learning of model for epochs.\n",
        "\n",
        "    Args:\n",
        "        \n",
        "        model: current model\n",
        "        optimizer: optimizer for this learning\n",
        "        criterion: loss function for this learning\n",
        "        epochs: number of epochs\n",
        "        batch_size: size of batch\n",
        "        device: set 'cpu' or 'cuda'\n",
        "\n",
        "    Returns: \n",
        "        dicts with losses and accuracies\n",
        "    \"\"\"\n",
        "\n",
        "    train_dataset, val_dataset, _ = get_datasets()\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    best_val_loss = 1\n",
        "    best_val_acc = 0\n",
        "    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n",
        "    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n",
        "    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n",
        "        for epoch in range(epochs):\n",
        "            train_loss, train_acc = fit_epoch(model, train_loader, criterion, optimizer, device)\n",
        "            print(\"loss\", train_loss)\n",
        "            val_loss, val_acc = eval_epoch(model, val_loader, criterion, device)\n",
        "            # если loss и acc на val, улучшили показатели, сохраняем модель,\n",
        "            # для будущих предсказаний\n",
        "            if best_val_loss >= val_loss and best_val_acc <= val_acc:\n",
        "                if (os.path.exists('./outs') == False):\n",
        "                    os.mkdir('./outs')\n",
        "\n",
        "                best_val_loss = val_loss\n",
        "                best_val_acc = val_acc\n",
        "                torch.save(model.state_dict(), './outs/best_model.pth')\n",
        "                print(f\"\\n\\nSave model's completed on {epoch+1} epoch's\")\n",
        "\n",
        "            wandb.log({\"train_loss\": train_loss, \"train_acc\": train_acc, \n",
        "                       \"val_loss\": val_loss, \"val_acc\": val_acc, \n",
        "                       \"epoch\": epoch})\n",
        "            pbar_outer.update(1)\n",
        "            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n",
        "                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n",
        "               \n",
        "\n",
        "\n",
        "def fit_epoch(\n",
        "        model: nn.Module,\n",
        "        train_loader: DataLoader,\n",
        "        criterion: Callable,\n",
        "        optimizer: torch.optim.Optimizer,\n",
        "        device: Callable\n",
        "    ) -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Проводим обучение на одном баче.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): используемая модель\n",
        "        train_loader (DataLoader): даталоадер для обучения\n",
        "        criterion (Callable): функция потерь\n",
        "        optimizer (torch.optim.Optimizer): оптимайзер\n",
        "        device (Callable): 'cpu' или 'cuda'\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float]: loss и accuracy\n",
        "    \"\"\"\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_data = 0\n",
        "  \n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds = torch.argmax(outputs, 1)\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_data += inputs.size(0)\n",
        "    train_loss = running_loss / processed_data\n",
        "    train_acc = running_corrects.cpu().numpy() / processed_data\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "def eval_epoch(\n",
        "        model: nn.Module, \n",
        "        val_loader: DataLoader, \n",
        "        criterion: Callable, \n",
        "        device: Callable\n",
        "    ) -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Проводим оценивание на одном баче.\n",
        "    Args:\n",
        "        model (nn.Module): используемая модель\n",
        "        val_loader (DataLoader): даталоадер для оценивания\n",
        "        criterion (Callable): функция потерь\n",
        "        device (Callable): 'cpu' или 'cuda'\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, float]: loss и accuracy\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    processed_size = 0\n",
        "\n",
        "    for inputs, labels in val_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            preds = torch.argmax(outputs, 1)\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        processed_size += inputs.size(0)\n",
        "    val_loss = running_loss / processed_size\n",
        "    val_acc = running_corrects.double() / processed_size\n",
        "    return val_loss, val_acc\n",
        "\n",
        "\n",
        "def prediction(\n",
        "        model: nn.Module, \n",
        "        test_loader: DataLoader, \n",
        "        device: Callable\n",
        "    ) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Определение класса для набора из test_loader.\n",
        "    Args:\n",
        "        model: модель для вычислений\n",
        "        test_loader: набор для определения класса\n",
        "        device: \"cpu\" или \"cuda\"\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: _description_\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        logits = []\n",
        "    \n",
        "        for inputs in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            model.eval()\n",
        "            outputs = model(inputs).cpu()\n",
        "            logits.append(outputs)\n",
        "            \n",
        "    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n",
        "    return probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EEADvgNXcCER"
      },
      "outputs": [],
      "source": [
        "\"\"\"Train model.\"\"\"\n",
        "\n",
        "def  train_model( \n",
        "        config: dict,\n",
        "        device: Callable = torch.device('cpu'),\n",
        "    ):\n",
        "    \"\"\"\n",
        "    Build all together: initialize the model,\n",
        "    optimizer and loss function.\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): set batch size\n",
        "        epochs (int): number of epochs\n",
        "        lr (float): learning rate\n",
        "        seed (int): seed for randoms\n",
        "        device : set \"cpu\" or \"cuda\"\n",
        "    \"\"\"\n",
        "\n",
        "    wandb.login()\n",
        "    with wandb.init(project=\"pipeline_competition\",config=config):\n",
        "        config = wandb.config\n",
        "        seed_everything(config.seed)\n",
        "        model = get_model().to(device)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        model_learning(model, optimizer, criterion, epochs=config.epochs,\n",
        "                       batch_size=config.batch_size, device=device)\n",
        "\n",
        "architecture=\"Inception_V3\"\n",
        "dataset=\"shift-cv-winter-2023\"\n",
        "epochs=1\n",
        "batch_size=4\n",
        "lr=0.001\n",
        "seed=42\n",
        "\n",
        "def train():\n",
        "    \"\"\" Определение гиперпараметров, запуск обучения. \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    config_for_training = dict(\n",
        "        architecture = architecture,  \n",
        "        dataset = dataset,\n",
        "        epochs = epochs,\n",
        "        batch_size = batch_size,\n",
        "        lr= lr,\n",
        "        seed = seed\n",
        "    )\n",
        "    train_model(config_for_training, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "XaWY7ZvWcho9",
        "outputId": "54eec41f-2887-4dd2-a413-e75116acaa48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:gofyodks) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">balmy-water-368</strong> at: <a href='https://wandb.ai/balakinakate2022/pipeline_competition/runs/gofyodks' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition/runs/gofyodks</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230323_041949-gofyodks/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:gofyodks). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230323_041953-k8gakx5c</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/balakinakate2022/pipeline_competition/runs/k8gakx5c' target=\"_blank\">woven-thunder-369</a></strong> to <a href='https://wandb.ai/balakinakate2022/pipeline_competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/balakinakate2022/pipeline_competition' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/balakinakate2022/pipeline_competition/runs/k8gakx5c' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition/runs/k8gakx5c</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss 0.6290224368000651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch: 100%|██████████| 1/1 [01:30<00:00, 90.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Save model's completed on 1 epoch's\n",
            "\n",
            "Epoch 001 train_loss: 0.6290     val_loss 0.6248 train_acc 0.6782 val_acc 0.6577\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train_acc</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>val_acc</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>train_acc</td><td>0.67818</td></tr><tr><td>train_loss</td><td>0.62902</td></tr><tr><td>val_acc</td><td>0.65766</td></tr><tr><td>val_loss</td><td>0.62481</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">woven-thunder-369</strong> at: <a href='https://wandb.ai/balakinakate2022/pipeline_competition/runs/k8gakx5c' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition/runs/k8gakx5c</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230323_041953-k8gakx5c/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932,
          "referenced_widgets": [
            "d81131712e4049edbf33e9feacd84ccf",
            "912e15e8a48e4c8b9ed516d9d7c26cd6",
            "1051706061794b7ebd4dabb6efa59ec6",
            "06e3f89d82724dcbbb71ef767ff8d467",
            "f6d7317bc2c34cb8992666aca29184b1",
            "050e631cd1d54326900ccd03c678bad7",
            "2ba585b36630410489d8702ffe97485c",
            "8cbd541d2006463984404c857717d9a9"
          ]
        },
        "id": "_xk2fUcrcjAt",
        "outputId": "8ac57e60-a6d4-4cb0-c748-9de6fc98d605"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. Additional properties are not allowed ('function' was unexpected)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 6hhkplnj\n",
            "Sweep URL: https://wandb.ai/balakinakate2022/pipeline_competition/sweeps/6hhkplnj\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: While tearing down the service manager. The following error has occurred: [Errno 32] Broken pipe\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9srag0h0 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 3e-05\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230323_044201-9srag0h0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/balakinakate2022/pipeline_competition/runs/9srag0h0' target=\"_blank\">daily-sweep-1</a></strong> to <a href='https://wandb.ai/balakinakate2022/pipeline_competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/balakinakate2022/pipeline_competition/sweeps/6hhkplnj' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition/sweeps/6hhkplnj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/balakinakate2022/pipeline_competition' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/balakinakate2022/pipeline_competition/sweeps/6hhkplnj' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition/sweeps/6hhkplnj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/balakinakate2022/pipeline_competition/runs/9srag0h0' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition/runs/9srag0h0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:9srag0h0) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">daily-sweep-1</strong> at: <a href='https://wandb.ai/balakinakate2022/pipeline_competition/runs/9srag0h0' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition/runs/9srag0h0</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230323_044201-9srag0h0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:9srag0h0). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d81131712e4049edbf33e9feacd84ccf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666866761665915, max=1.0)…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230323_044202-9srag0h0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/balakinakate2022/pipeline_competition/runs/9srag0h0' target=\"_blank\">daily-sweep-1</a></strong> to <a href='https://wandb.ai/balakinakate2022/pipeline_competition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/balakinakate2022/pipeline_competition/sweeps/6hhkplnj' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition/sweeps/6hhkplnj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/balakinakate2022/pipeline_competition' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View sweep at <a href='https://wandb.ai/balakinakate2022/pipeline_competition/sweeps/6hhkplnj' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition/sweeps/6hhkplnj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/balakinakate2022/pipeline_competition/runs/9srag0h0' target=\"_blank\">https://wandb.ai/balakinakate2022/pipeline_competition/runs/9srag0h0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss 0.580927411595861\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch:  10%|█         | 1/10 [01:14<11:07, 74.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Save model's completed on 1 epoch's\n",
            "\n",
            "Epoch 001 train_loss: 0.5809     val_loss 0.3772 train_acc 0.6942 val_acc 0.8634\n",
            "loss 0.21427644156777226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch:  20%|██        | 2/10 [02:21<09:21, 70.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Save model's completed on 2 epoch's\n",
            "\n",
            "Epoch 002 train_loss: 0.2143     val_loss 0.1234 train_acc 0.9229 val_acc 0.9655\n",
            "loss 0.10675372146778517\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch:  30%|███       | 3/10 [03:28<08:00, 68.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Save model's completed on 3 epoch's\n",
            "\n",
            "Epoch 003 train_loss: 0.1068     val_loss 0.0911 train_acc 0.9630 val_acc 0.9730\n"
          ]
        }
      ],
      "source": [
        "sweep_configuration = {\n",
        "        'method': 'random',\n",
        "        'name': 'sweep',\n",
        "\n",
        "        'metric': {\n",
        "            'goal': 'maximize', \n",
        "            'name': 'val_acc_epoch'\n",
        "            },\n",
        "        'parameters': {\n",
        "            'batch_size': {'values': [2, 8, 32]},\n",
        "            'epochs': {'values': [10]},\n",
        "            'lr': {'values': [0.003, 0.0003, 0.00003]}\n",
        "        },\n",
        "        \"function\": 'train'\n",
        "    }\n",
        "\n",
        "sweep_id = wandb.sweep(sweep=sweep_configuration, project='pipeline_competition')\n",
        "\n",
        "def sweep_func():\n",
        "    \"\"\"Подбор гиперпараметров с помощью sweep W&B.\"\"\"\n",
        "    run = wandb.init()\n",
        "\n",
        "    wandb.init(project=\"pipeline\")\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = get_model().to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=wandb.config.lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    model_learning(model, optimizer, criterion, epochs=wandb.config.epochs,\n",
        "                    batch_size=wandb.config.batch_size, device=device)\n",
        "\n",
        "wandb.agent(sweep_id, function=sweep_func, count=9)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "050e631cd1d54326900ccd03c678bad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06e3f89d82724dcbbb71ef767ff8d467": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1051706061794b7ebd4dabb6efa59ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ba585b36630410489d8702ffe97485c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cbd541d2006463984404c857717d9a9",
            "value": 1
          }
        },
        "2ba585b36630410489d8702ffe97485c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cbd541d2006463984404c857717d9a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "912e15e8a48e4c8b9ed516d9d7c26cd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6d7317bc2c34cb8992666aca29184b1",
            "placeholder": "​",
            "style": "IPY_MODEL_050e631cd1d54326900ccd03c678bad7",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "d81131712e4049edbf33e9feacd84ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_912e15e8a48e4c8b9ed516d9d7c26cd6",
              "IPY_MODEL_1051706061794b7ebd4dabb6efa59ec6"
            ],
            "layout": "IPY_MODEL_06e3f89d82724dcbbb71ef767ff8d467"
          }
        },
        "f6d7317bc2c34cb8992666aca29184b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
